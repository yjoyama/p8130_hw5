---
title: "Homework5"
author: "Yuki Joyama"
date: "2023-12-12"
output: 
  pdf_document:
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = FALSE,
  message=FALSE,
  warning=FALSE)

library(tidyverse)
library(ggplot2)
library(faraway)
library(gtsummary)
library(flextable)
library(leaps)
library(glmnet)
library(GGally)
library(stargazer)
library(caret)

# import data set
df = state.x77 |> 
  as_tibble(rownames = "state") |> 
  mutate(
    state = as_factor(state)
  ) |> 
  janitor::clean_names()
```

# Problem 1
a) The following table shows the descriptive statistics for all variables of interest in 50 States. 
```{r}
df |> 
  select(-state) |> 
  tbl_summary(
    statistic = list(
      all_continuous() ~ "{mean} / {median} ({sd})",
      all_categorical() ~ "{n} ({p}%)"
    ),
    digits = all_continuous() ~ 1,
    label = list(
      population ~ "Population",
      income ~ "Income per capita",
      illiteracy ~ "Illiteracy (%)",
      life_exp ~ "Life Expectancy (years)",
      murder ~ "Murder rate (per 100,000)",
      hs_grad ~ "High graduates (%)",
      frost ~ "Number of days below freezing",
      area ~ "Land area (mile^2)"
    )
  ) |> 
  as_flex_table()
```

b) 
```{r}
# normality test by shapiro-wilk test
sw_t = tibble(num = 2:9) |> 
  mutate(
    var = colnames(df)[-1],
    sw = map(num, \(i) shapiro.test(df[[i]])),
    sw_results = map(sw, broom::tidy)
  ) |> 
  unnest(sw_results)

sw_t |> 
  select(var, statistic, p.value) |>
  mutate_at(2:3, round, 3) |> 
  mutate(
    p.value = ifelse(p.value < 0.001, "<0.001", p.value)
  ) |> 
  knitr::kable()
```

The results of Shapiro-Wilk test indicates that variable `population`, `illiteracy`, `murder`, `hs_grad`, and `area` is not normally distributed.  
The histogram and Q-Q plots for these variables are as follows:

```{r fig.width=10, fig.height=16}
df_val = df |> 
  select(population, illiteracy, murder, hs_grad, area)
a = colnames(df_val)[1:5]

par(mfrow = c(5, 2), mar = c(4, 4, 2, 1))

for (i in 1:5) {
  sub <- df_val[[i]]
  
  # Create a new plot for each iteration
  hist(sub, main = paste("Hist. of", a[i], sep = " "), xlab = a[i])
  qqnorm(sub, main = paste("Q-Q Plot of", a[i], sep = " "))
  qqline(sub)
}
```

Given the shape of the histograms, I will log-transform `population`, `illiteracy`, and `area`.

```{r}
df_trans = df |> 
  mutate(
    population = log(population),
    illiteracy = log(illiteracy),
    area = log(area)
  )
```

Now, let's check these histograms.

```{r fig.width=10, fig.height=4}
par(mfrow = c(1, 3))
hist(df_trans$population, main = "Hist. of population", xlab = "population")
hist(df_trans$illiteracy, main = "Hist. of illiteracy", xlab = "illiteracy")
hist(df_trans$area, main = "Hist. of area", xlab = "area")
```

I will use the data set including the log-transformed variables for the later analysis. Let's check the correlation between each variable and linear regression model including all variables. 


```{r}
df_val = df_trans |> 
  select(-state)

# plot pairwise correlations
ggcorr(df_val, label = T)

# fit regression using all predictors
life_lm = lm(life_exp ~ ., data = df_val)
summary(life_lm)
```

c) Automatic procedures 
In this section, I will use backward and forward procedures. 
```{r}
# backward
step(life_lm, direction = "backward")

# forward
# fit using one function
intercept_only = lm(life_exp ~ 1, data = df_val)
step(intercept_only, direction = "forward", scope = formula(life_lm))
```

The both procedures generated the same model (variables included in the final model: `murder`, `hs_grad`, `population`, `frost`). There does not appear to be a close call, as the elimination/addition of each variable consistently decreases the AIC value and indicates a better model fit. Therefore, I would keep all the variables suggested by the procedure.  
Intuitively, we could assume that there is an association between `illiteracy` and `HS graduation rate`. My subset does not include both, so instead of checking for multicollinearity, let's examine correlation.

```{r}
cor(df_val$hs_grad, df_val$illiteracy)
```

There seems to be a moderate negative association between the two variables.

d) Criterion-based procedures  
```{r}
b = regsubsets(life_exp ~ ., data = df_val)
rs = summary(b)
rs

# plot of Cp and Adj-R2 as functions of parameters
par(mfrow=c(1,2))
plot(1:7, rs$cp, xlab="No of parameters", ylab="Cp Statistic")
abline(0,1)
plot(1:7, rs$adjr2, xlab="No of parameters", ylab="Adj R2")
```

The Mallow's Cp criterion and Adjusted $R^2$ suggests that the model with four parameters (`population`, `murder`, `hs_grad`, `frost`) is the best fit. 

e) The LASSO method  
```{r}
df_val = df_val |> 
  relocate(life_exp)

# fit a LASSO with lambda = 5
fit_5 = glmnet(as.matrix(df_val[2:8]), df_val$life_exp, lambda = 5)
coef(fit_5)

# fit a LASSO with lambda = 0.1
fit_0.1 = glmnet(as.matrix(df_val[2:8]), df_val$life_exp, lambda = 0.1)
coef(fit_0.1)

# using cross validation to choose lambda
lambda_seq = 10^seq(-3, 0, by = .1)
set.seed(1)
cv_object = cv.glmnet(
  as.matrix(df_val[2:8]), 
  df_val$life_exp,
  lambda = lambda_seq,
  nfolds = 5
)
cv_object

# plot the CV results
tibble(
  lambda = cv_object$lambda,
  mean_cv_error = cv_object$cvm
) |> 
  ggplot(aes(x = lambda, y = mean_cv_error)) +
  geom_point()

# extract the exact minimum lambda from the CV object
cv_object$lambda.min

# refit the lasso model with the best lambda
fit_bestcv = glmnet(as.matrix(df_val[2:8]), df_val$life_exp, lambda = cv_object$lambda.min)
coef(fit_bestcv)
```

The lambda value that minimizes the test MSE turns out to be `r cv_object$lambda.min`. The final model produced by the optimal lambda value does not include `income` and `illiteracy` because they were not influential enough. 

f) Compare the subsets from c, d, and e  
```{r}
# prepare 10-fold 
# use 10-fold validation and create the training sets
train = trainControl(method = "cv", number = 10)

# model validation (c and d)
# fit the model
fit_lm_val = train(
  life_exp ~ murder + hs_grad + population + frost,
  data = df_val,
  trControl = train,
  method = 'lm',
  na.action = na.pass
)

print(fit_lm_val)

# model validation (e)
# fit the Lasso model using train function
fit_lasso_val = train(
  life_exp ~ murder + hs_grad + population + frost + area,
  data = df_val,
  trControl = train,
  method = 'glmnet',
  tuneGrid = expand.grid(alpha = 1, lambda = cv_object$lambda.min),
  na.action = na.pass
)

print(fit_lasso_val)
```

The Root Mean Square Errors (RMSEs) from linear regression model (selected by c and d) and LASSO regression model (by e) indicate that the linear model has slightly better predictive ability in the testing data set. Thus, I will employ the linear regression model as my final model.  

Let's check the model assumptions.  
```{r}

```


g) Findings











